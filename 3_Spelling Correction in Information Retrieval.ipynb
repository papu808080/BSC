{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24d2e070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Spelling Correction and Document Retrieval ===\n",
      "Corrected Query: retrieval\n",
      "Query: 'retrievel' → Corrected Documents: [2, 3]\n",
      "Corrected Query: document indexing\n",
      "Query: 'documnt indexing' → Corrected Documents: [2]\n",
      "Corrected Query: web mining\n",
      "Query: 'web minng' → Corrected Documents: [3]\n",
      "Corrected Query: structured data\n",
      "Query: 'strctured data' → Corrected Documents: [1]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class InvertedIndex:\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "        self.index = defaultdict(set)\n",
    "        self.vocabulary = set()\n",
    "\n",
    "        for doc_id, text in self.documents.items():\n",
    "            words = text.lower().split()\n",
    "            self.vocabulary.update(words)\n",
    "            for word in words:\n",
    "                self.index[word].add(doc_id)\n",
    "\n",
    "    def search(self, query):\n",
    "        corrected_words = [self.correct_spelling(word) for word in query.lower().split()]\n",
    "        print(f\"Corrected Query: {' '.join(corrected_words)}\")\n",
    "\n",
    "        result_sets = [self.index[word] for word in corrected_words if word in self.index]\n",
    "        return set.intersection(*result_sets) if result_sets else set()\n",
    "\n",
    "    def correct_spelling(self, word):\n",
    "        if word in self.vocabulary:\n",
    "            return word\n",
    "        return min(self.vocabulary, key=lambda vocab_word: self.levenshtein_distance(word, vocab_word))\n",
    "\n",
    "    def levenshtein_distance(self, s1, s2):\n",
    "        dp = [[0 for _ in range(len(s2) + 1)] for _ in range(len(s1) + 1)]\n",
    "\n",
    "        for i in range(len(s1) + 1): dp[i][0] = i\n",
    "        for j in range(len(s2) + 1): dp[0][j] = j\n",
    "\n",
    "        for i in range(1, len(s1) + 1):\n",
    "            for j in range(1, len(s2) + 1):\n",
    "                cost = 0 if s1[i-1] == s2[j-1] else 1\n",
    "                dp[i][j] = min(dp[i-1][j] + 1, dp[i][j-1] + 1, dp[i-1][j-1] + cost)\n",
    "\n",
    "        return dp[len(s1)][len(s2)]\n",
    "\n",
    "documents = {\n",
    "   1: \"Web content extraction involves retrieving structured data\",\n",
    "   2: \"Search engines use document indexing for efficient retrieval\",\n",
    "   3: \"Document retrieval is important in web mining applications\",\n",
    "   4: \"Indexing helps in retrieving relevant documents based on query terms\"\n",
    "}\n",
    "\n",
    "index = InvertedIndex(documents)\n",
    "queries = [\"retrievel\", \"documnt indexing\", \"web minng\", \"strctured data\"]\n",
    "\n",
    "print(\"\\n=== Spelling Correction and Document Retrieval ===\")\n",
    "for query in queries:\n",
    "   result = index.search(query)\n",
    "   print(f\"Query: '{query}' → Corrected Documents: {sorted(result) if result else 'No matching documents'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
